{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pickle as pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "import sklearn\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "from transformers import AutoTokenizer, AutoConfig, AutoModelForSequenceClassification, Trainer, TrainingArguments, RobertaConfig, RobertaTokenizer, RobertaForSequenceClassification, BertTokenizer\n",
    "from load_data import *\n",
    "from train import *\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from GPUtil import showUtilization\n",
    "from tqdm.notebook import tqdm"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "source": [
    "class FeatureExtractionBert(nn.Module):\n",
    "    def __init__(self, MODEL_NAME):\n",
    "        super().__init__()\n",
    "        self.config =  AutoConfig.from_pretrained(MODEL_NAME)\n",
    "        self.Bert = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, config=self.config).bert\n",
    "        \n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        position_ids=None,\n",
    "        head_mask=None,\n",
    "        inputs_embeds=None,\n",
    "        labels=None,\n",
    "        output_attentions=None,\n",
    "        output_hidden_states=None,\n",
    "        return_dict=None,\n",
    "    ):\n",
    "\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        outputs = self.Bert(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "\n",
    "        return outputs"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "source": [
    "# 가장 점수 높았던 베이스라인 모델 불러오기\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "features = FeatureExtractionBert('./results/checkpoint-2500').to(device)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "source": [
    "# 특성 추출할 데이터 로드\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"klue/bert-base\")\n",
    "\n",
    "# load dataset\n",
    "train_dataset = load_data(\"../dataset/train/train.csv\")\n",
    "dev_dataset = load_data(\"../dataset/train/dev.csv\") # validation용 데이터는 따로 만드셔야 합니다.\n",
    "\n",
    "train_label = label_to_num(train_dataset['label'].values)\n",
    "dev_label = label_to_num(dev_dataset['label'].values)\n",
    "\n",
    "# tokenizing dataset\n",
    "tokenized_train = tokenized_dataset(train_dataset, tokenizer)\n",
    "tokenized_dev = tokenized_dataset(dev_dataset, tokenizer)\n",
    "\n",
    "# make dataset for pytorch.\n",
    "RE_train_dataset = RE_Dataset(tokenized_train, train_label)\n",
    "RE_dev_dataset = RE_Dataset(tokenized_dev, dev_label)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "source": [
    "showUtilization()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 35% |\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "source": [
    "train_dataloader = DataLoader(RE_train_dataset, batch_size=16, shuffle=False)\n",
    "dev_dataloader = DataLoader(RE_dev_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "def FeatureExtraction(feature_extractor, dataloader):\n",
    "    for param in feature_extractor.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    feature_extractor.eval()\n",
    "    outputs = []\n",
    "    for i, data in enumerate(tqdm(dataloader)):\n",
    "        with torch.no_grad():\n",
    "            outputs.append(feature_extractor(\n",
    "                input_ids=data['input_ids'].to(device),\n",
    "                attention_mask=data['attention_mask'].to(device),\n",
    "                token_type_ids=data['token_type_ids'].to(device)\n",
    "                ).pooler_output)\n",
    "    return torch.cat(outputs).detach().cpu().numpy()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "torch.cat(outputs).size()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([32470, 768])"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "source": [
    "ml_train = FeatureExtraction(features, train_dataloader)\n",
    "ml_valid = FeatureExtraction(features, dev_dataloader)"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "995b801ac7034a92a438aa5dd772cda2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=2030.0), HTML(value='')))"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daa31bde98ac4c87b3b6dd4ef74deec1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=486.0), HTML(value='')))"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "source": [
    "ml_train.shape, ml_valid.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((32470, 768), (7765, 768))"
      ]
     },
     "metadata": {},
     "execution_count": 123
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "len(train_label)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "32470"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# PCA"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=0.95)\n",
    "ml_train_reduced = pca.fit_transform(ml_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "ml_train_reduced.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(32470, 41)"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "ml_valid_reduced = pca.transform(ml_valid)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "ml_valid_reduced.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(7765, 41)"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Catboost"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "# !pip install catboost"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Collecting catboost\n",
      "  Downloading catboost-1.0.0-cp38-none-manylinux1_x86_64.whl (76.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 76.4 MB 269 kB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pandas>=0.24.0 in /opt/conda/lib/python3.8/site-packages (from catboost) (1.1.5)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.8/site-packages (from catboost) (1.7.1)\n",
      "Collecting plotly\n",
      "  Downloading plotly-5.3.1-py2.py3-none-any.whl (23.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 23.9 MB 54.6 MB/s eta 0:00:01    |███▉                            | 2.9 MB 54.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting matplotlib\n",
      "  Downloading matplotlib-3.4.3-cp38-cp38-manylinux1_x86_64.whl (10.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 10.3 MB 62.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting graphviz\n",
      "  Downloading graphviz-0.17-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /opt/conda/lib/python3.8/site-packages (from catboost) (1.19.2)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from catboost) (1.15.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.8/site-packages (from pandas>=0.24.0->catboost) (2020.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.8/site-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
      "Collecting tenacity>=6.2.0\n",
      "  Downloading tenacity-8.0.1-py3-none-any.whl (24 kB)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.3.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 64.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib->catboost) (2.4.7)\n",
      "Collecting cycler>=0.10\n",
      "  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib->catboost) (8.1.0)\n",
      "Installing collected packages: tenacity, plotly, kiwisolver, cycler, matplotlib, graphviz, catboost\n",
      "Successfully installed catboost-1.0.0 cycler-0.10.0 graphviz-0.17 kiwisolver-1.3.2 matplotlib-3.4.3 plotly-5.3.1 tenacity-8.0.1\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "from catboost import CatBoostClassifier, Pool"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "train_data = Pool(data=ml_train_reduced, label=train_label)\n",
    "valid_data = Pool(data=ml_valid_reduced, label=dev_label)\n",
    "\n",
    "model_cat_reduced = CatBoostClassifier(task_type=\"GPU\", devices='cuda:0')\n",
    "model_cat_reduced.fit(train_data, eval_set=valid_data, use_best_model=True, early_stopping_rounds=100, verbose=100)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Learning rate set to 0.149448\n",
      "0:\tlearn: 1.5059796\ttest: 1.7172364\tbest: 1.7172364 (0)\ttotal: 13.7ms\tremaining: 13.6s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Warning: less than 75% gpu memory available for training. Free: 21272.5 Total: 32510.5\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "100:\tlearn: 0.3218465\ttest: 0.8715834\tbest: 0.8715834 (100)\ttotal: 1.14s\tremaining: 10.2s\n",
      "200:\tlearn: 0.2631672\ttest: 0.8578229\tbest: 0.8532011 (167)\ttotal: 2.18s\tremaining: 8.68s\n",
      "bestTest = 0.8532010876\n",
      "bestIteration = 167\n",
      "Shrink model to first 168 iterations.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7fec3231e940>"
      ]
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "y_pred_valid_reduced = model_cat_reduced.predict(ml_valid_reduced)\n",
    "y_true_valid = dev_label\n",
    "\n",
    "print(f'Accuracy: {accuracy_score(y_true_valid, y_pred_valid_reduced)}, f1_score: {f1_score(y_true_valid, y_pred_valid_reduced, average=\"micro\")}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy: 0.7426915647134579, f1_score: 0.742691564713458\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "train_data = Pool(data=ml_train, label=train_label)\n",
    "valid_data = Pool(data=ml_valid, label=dev_label)\n",
    "\n",
    "model_cat = CatBoostClassifier(task_type=\"GPU\", devices='cuda:0')\n",
    "model_cat.fit(train_data, eval_set=valid_data, use_best_model=True, early_stopping_rounds=100, verbose=100)\n",
    "\n",
    "y_pred_valid = model_cat.predict(ml_valid)\n",
    "y_true_valid = dev_label\n",
    "\n",
    "print(f'Accuracy: {accuracy_score(y_true_valid, y_pred_valid)}, f1_score: {f1_score(y_true_valid, y_pred_valid, average=\"micro\")}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Learning rate set to 0.149448\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Warning: less than 75% gpu memory available for training. Free: 21272.5 Total: 32510.5\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0:\tlearn: 1.7300992\ttest: 1.7983392\tbest: 1.7983392 (0)\ttotal: 41.1ms\tremaining: 41s\n",
      "100:\tlearn: 0.3280669\ttest: 0.8607522\tbest: 0.8591111 (98)\ttotal: 3.65s\tremaining: 32.5s\n",
      "200:\tlearn: 0.2734966\ttest: 0.8402805\tbest: 0.8386717 (194)\ttotal: 7.28s\tremaining: 28.9s\n",
      "300:\tlearn: 0.2353541\ttest: 0.8417031\tbest: 0.8375543 (261)\ttotal: 10.8s\tremaining: 25s\n",
      "bestTest = 0.8375542674\n",
      "bestIteration = 261\n",
      "Shrink model to first 262 iterations.\n",
      "Accuracy: 0.7451384417256922, f1_score: 0.7451384417256922\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Submission"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "source": [
    "from inference import num_to_label, load_test_dataset"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "source": [
    "test_dataset_dir = \"../dataset/test/test_data.csv\"\n",
    "test_id, test_dataset, test_label = load_test_dataset(test_dataset_dir, tokenizer)\n",
    "Re_test_dataset = RE_Dataset(test_dataset ,test_label)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "source": [
    "test_dataloader = DataLoader(Re_test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "ml_test = FeatureExtraction(features, test_dataloader)"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8c64f8fd65d44439fd2f017d0e07bbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=486.0), HTML(value='')))"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "source": [
    "output_pred = num_to_label(np.argmax(model_cat.predict_proba(ml_test), axis=-1))\n",
    "output_prob = model_cat.predict_proba(ml_test).tolist()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "source": [
    "output = pd.DataFrame({'id':test_id,'pred_label':output_pred,'probs':output_prob,})"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "source": [
    "output.to_csv('./prediction/bert_base_catboost.csv', index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "source": [
    "# PCA\n",
    "ml_test_reduced = pca.transform(ml_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "source": [
    "output_pred = num_to_label(np.argmax(model_cat_reduced.predict_proba(ml_test_reduced), axis=-1))\n",
    "output_prob = model_cat_reduced.predict_proba(ml_test_reduced).tolist()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "source": [
    "output = pd.DataFrame({'id':test_id,'pred_label':output_pred,'probs':output_prob,})\n",
    "output.to_csv('./prediction/bert_base_catboost_pca.csv', index=False)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}